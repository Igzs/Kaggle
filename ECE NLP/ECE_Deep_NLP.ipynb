{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge you will be building a model that automatically determines logical entailment between two sentences.  \n",
    "The model for this task we chose is a Bidirectionnial LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Bidirectional, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import train and test csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Data/dataset_train.csv\",sep='\\t', index_col='index')\n",
    "test_df = pd.read_csv(\"Data/dataset_test_no_labels.csv\",sep='\\t',index_col='index')\n",
    "labels = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_1    0\n",
      "sentence_2    0\n",
      "label         0\n",
      "dtype: int64\n",
      "sentence_1    0\n",
      "sentence_2    0\n",
      "dtype: int64\n",
      "index\n",
      "0               neutral\n",
      "1            entailment\n",
      "2            entailment\n",
      "3            entailment\n",
      "4               neutral\n",
      "              ...      \n",
      "392657    contradiction\n",
      "392658          neutral\n",
      "392659       entailment\n",
      "392660          neutral\n",
      "392661          neutral\n",
      "Name: label, Length: 392662, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isna().sum())\n",
    "print(test_df.isna().sum())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Conceptually cream skimming has two basic dimensions - product and geography.',\n",
       "       'Product and geography are what make cream skimming work. ',\n",
       "       'neutral'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conceptually cream skimming has two basic dimensions - product and geography.'\n",
      " 'you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the Braves decide to call to recall a guy from triple A then a double A guy goes up to replace him and a single A guy goes up to replace him'\n",
      " 'One of our number will carry out your instructions minutely.' ...\n",
      " 'Houseboats are a beautifully preserved tradition of the heyday of the British Raj.'\n",
      " 'Obituaries fondly recalled his on-air debates and two thumbs up salutes with fellow reviewer Roger Ebert on their eponymous syndicated TV show.'\n",
      " 'in that other you know uh that i should do it or that or just to think about doing it rat her than having someone  tell him to do it i know that was a big thing in our house for a long time was that if i wanted my husband to do something to help']\n"
     ]
    }
   ],
   "source": [
    "print(train_df['sentence_1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 100\n",
    "max_vocabulary_size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = train_df['sentence_1'].values\n",
    "sentence_1_words = [line.split() for line in sentence_1]\n",
    "assert( len(sentence_1_words) == len(sentence_1))\n",
    "\n",
    "sentence_2 = train_df['sentence_2'].values\n",
    "sentence_2_words = [line.split() for line in sentence_2]\n",
    "assert( len(sentence_2_words) == len(sentence_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392662"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_sentence_1_words = [item for sublist in sentence_1_words for item in sublist]\n",
    "flat_sentence_2_words = [item for sublist in sentence_2_words for item in sublist]\n",
    "flat_words = flat_sentence_1_words + flat_sentence_2_words\n",
    "assert(len(flat_words) == len(flat_sentence_1_words)+len(flat_sentence_2_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(set(flat_words))\n",
    "word_index = dict((c, i) for i, c in enumerate(words))\n",
    "word_index_inversed = dict((i, c) for i, c in enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_vocabulary(corpus):\n",
    "    counter = Counter(corpus)\n",
    "    allowed_words = set([item[0] for item in counter.most_common(max_vocabulary_size)])\n",
    "    return [word for word in corpus if word in allowed_words]\n",
    "words = limit_vocabulary(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the input sentences to integer sequences using tf tokenizer.  \n",
    "We also need to pad the sequences to have them all at the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_vocabulary_size, char_level=False)\n",
    "tokenizer.fit_on_texts(words)\n",
    "sentence_1 =tokenizer.texts_to_sequences(train_df[\"sentence_1\"])\n",
    "sentence_2 = tokenizer.texts_to_sequences(train_df[\"sentence_2\"])\n",
    "sentence_1_seq = sequence.pad_sequences(sentence_1, maxlen=max_sequence_length, value=0,truncating=\"post\",padding=\"post\")\n",
    "sentence_2_seq  = sequence.pad_sequences( sentence_2,maxlen=max_sequence_length, value=0,truncating=\"post\",padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "tmp.append(sentence_1_seq)\n",
    "tmp.append(sentence_2_seq)\n",
    "X = np.array(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_labels(labels,inverse=False):\n",
    "    convert_dict = {\n",
    "      'entailment': 0,\n",
    "      'neutral': 1,\n",
    "      'contradiction': 2\n",
    "    }\n",
    "    convert_dict_inverse = {\n",
    "      0: 'entailment',\n",
    "      1: 'neutral',\n",
    "      2: 'contradiction'\n",
    "    }\n",
    "    new_labels=[]\n",
    "    if inverse:\n",
    "        new_labels.append(convert_dict_inverse[labels])\n",
    "    else:\n",
    "        for label in labels:\n",
    "            new_labels.append(convert_dict[label])\n",
    "    \n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = translate_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(words)\n",
    "vector_size = 50\n",
    "batch_size = 1024\n",
    "embedding_size = 64\n",
    "hidden_size = 64\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64000"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size*embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell is useful to reset the model and to not get any errors during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "from tensorflow.keras.backend import set_session\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "config_proto = tf.ConfigProto()\n",
    "off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "session = tf.Session(config=config_proto)\n",
    "set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "sentence_1 = Sequential()\n",
    "sentence_1.add(Embedding(vocabulary_size,embedding_size))\n",
    "\n",
    "               \n",
    "sentence_2 = Sequential()\n",
    "sentence_2.add(Embedding(vocabulary_size,embedding_size))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_concat = concatenate([sentence_1.output, sentence_2.output])\n",
    "model_concat = Bidirectional(tf.keras.layers.LSTM(hidden_size))(model_concat)\n",
    "model_concat = Dense(hidden_size, activation='relu')(model_concat)\n",
    "model_concat = Dense(3, activation='softmax')(model_concat)\n",
    "model = Model(inputs=[sentence_1.input, sentence_2.input], outputs=model_concat)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "embedding_input (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1_input (InputLayer)  [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 64)     64000       embedding_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 64)     64000       embedding_1_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, 128)    0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 128)          98816       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           8256        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            195         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 235,267\n",
      "Trainable params: 235,267\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 314129 samples, validate on 78533 samples\n",
      "Epoch 1/10\n",
      "314129/314129 [==============================] - 507s 2ms/sample - loss: 0.9537 - acc: 0.5248 - val_loss: 0.9610 - val_acc: 0.5165\n",
      "Epoch 2/10\n",
      "314129/314129 [==============================] - 506s 2ms/sample - loss: 0.9476 - acc: 0.5302 - val_loss: 0.9607 - val_acc: 0.5144\n",
      "Epoch 3/10\n",
      "314129/314129 [==============================] - 515s 2ms/sample - loss: 0.9428 - acc: 0.5343 - val_loss: 0.9574 - val_acc: 0.5178\n",
      "Epoch 4/10\n",
      "314129/314129 [==============================] - 533s 2ms/sample - loss: 0.9377 - acc: 0.5382 - val_loss: 0.9540 - val_acc: 0.5229\n",
      "Epoch 5/10\n",
      "314129/314129 [==============================] - 575s 2ms/sample - loss: 0.9328 - acc: 0.5424 - val_loss: 0.9528 - val_acc: 0.5219\n",
      "Epoch 6/10\n",
      "314129/314129 [==============================] - 611s 2ms/sample - loss: 0.9280 - acc: 0.5459 - val_loss: 0.9554 - val_acc: 0.5226\n",
      "Epoch 7/10\n",
      "314129/314129 [==============================] - 643s 2ms/sample - loss: 0.9232 - acc: 0.5502 - val_loss: 0.9487 - val_acc: 0.5281\n",
      "Epoch 8/10\n",
      "314129/314129 [==============================] - 679s 2ms/sample - loss: 0.9184 - acc: 0.5534 - val_loss: 0.9485 - val_acc: 0.5308\n",
      "Epoch 9/10\n",
      "314129/314129 [==============================] - 708s 2ms/sample - loss: 0.9139 - acc: 0.5578 - val_loss: 0.9486 - val_acc: 0.5306\n",
      "Epoch 10/10\n",
      "314129/314129 [==============================] - 754s 2ms/sample - loss: 0.9096 - acc: 0.5600 - val_loss: 0.9459 - val_acc: 0.5329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29bdfb3a1d0>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "           [X[0],X[1]],num_labels, validation_split=0.2, batch_size=batch_size, epochs=epochs,verbose=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence_1 = test_df[\"sentence_1\"].values\n",
    "test_sentence_2 = test_df[\"sentence_2\"].values\n",
    "\n",
    "test_sentence_1 =tokenizer.texts_to_sequences(test_df[\"sentence_1\"])\n",
    "test_sentence_2 = tokenizer.texts_to_sequences(test_df[\"sentence_2\"])\n",
    "test_sentence_1_seq = sequence.pad_sequences(test_sentence_1, maxlen=max_sequence_length, value=0,truncating=\"post\",padding=\"post\")\n",
    "test_sentence_2_seq  = sequence.pad_sequences(test_sentence_2,maxlen=max_sequence_length, value=0,truncating=\"post\",padding=\"post\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "tmp.append(test_sentence_1_seq)\n",
    "tmp.append(test_sentence_2_seq)\n",
    "\n",
    "X_test = np.array(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19647/19647 [==============================] - 58s 3ms/sample\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict([X_test[0],X_test[1]],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels=pd.DataFrame(columns=[\"index\",\"label\"])\n",
    "\n",
    "for index,pred in enumerate(predict):\n",
    "    real_label = translate_labels(np.round(np.argmax(pred)),inverse=True)\n",
    "    real_label = str(real_label).strip('[]').replace(\"'\",\"\")\n",
    "    pred_labels = pred_labels.append({'index':index, 'label':real_label},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19642</td>\n",
       "      <td>19642</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19643</td>\n",
       "      <td>19643</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19644</td>\n",
       "      <td>19644</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19645</td>\n",
       "      <td>19645</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19646</td>\n",
       "      <td>19646</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19647 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index          label\n",
       "0          0     entailment\n",
       "1          1     entailment\n",
       "2          2        neutral\n",
       "3          3  contradiction\n",
       "4          4  contradiction\n",
       "...      ...            ...\n",
       "19642  19642  contradiction\n",
       "19643  19643        neutral\n",
       "19644  19644        neutral\n",
       "19645  19645        neutral\n",
       "19646  19646     entailment\n",
       "\n",
       "[19647 rows x 2 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               index,label\n",
      "0             0,entailment\n",
      "1             1,entailment\n",
      "2                2,neutral\n",
      "3          3,contradiction\n",
      "4          4,contradiction\n",
      "...                    ...\n",
      "19642  19642,contradiction\n",
      "19643        19643,neutral\n",
      "19644        19644,neutral\n",
      "19645        19645,neutral\n",
      "19646     19646,entailment\n",
      "\n",
      "[19647 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "TableBIS = pd.read_csv(\"submission.csv\", sep=\"\\t\")\n",
    "print(TableBIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
